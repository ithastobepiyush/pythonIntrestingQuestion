{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6GcQ/uvr5MmrB/Z1Im1Zh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanu-N-Prabhu/Python/blob/master/Law_of_Demeter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why the Law of Demeter Is the Missing Piece in Your Machine Learning Pipeline\n",
        "\n",
        "## Keep your objects from reaching too far and your code from breaking too often.\n",
        "\n",
        "\n",
        "| ![space-1.jpg](https://github.com/Tanu-N-Prabhu/Python/blob/master/Img/christina-wocintechchat-com-SqmaKDvcIso-unsplash.jpg?raw=true) |\n",
        "|:--:|\n",
        "|Photo by <a href=\"https://unsplash.com/@wocintechchat?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Christina @ wocintechchat.com</a> on <a href=\"https://unsplash.com/photos/shallow-focus-photo-of-python-book-SqmaKDvcIso?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a>|\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Have you seen ML code like this?\n",
        "\n",
        "```\n",
        "experiment.trainer.model.optimizer.lr_scheduler.step()\n",
        "```\n",
        "\n",
        "It works until it doesn’t. Any change in how the optimizer or scheduler is structured breaks everything. That’s where the Law of Demeter steps in.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Problem\n",
        "\n",
        "* Modern ML systems use nested components:\n",
        "\n",
        "* Pipelines contain trainers\n",
        "\n",
        "* Trainers contain models\n",
        "\n",
        "* Models use optimizers\n",
        "\n",
        "* Optimizers might have learning rate schedulers\n",
        "\n",
        "Calling deeply nested methods ties your code to a fragile internal structure.\n",
        "\n",
        "---\n",
        "\n",
        "### What is the Law of Demeter?\n",
        "Formulated in 1987, it’s a guideline that says:\n",
        "\n",
        "> \"An object should only communicate with its immediate friends.\"\n",
        "\n",
        "It limits how many objects deep you go in a call chain.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Bad Code Example\n",
        "\n",
        "```\n",
        "# Violates Law of Demeter\n",
        "pipeline.trainer.model.fit(X, y)\n",
        "```\n",
        "\n",
        "Here, the outer class knows too much about inner components.\n",
        "\n",
        "\n",
        "### Refactored Code (Demeter Compliant)\n",
        "\n",
        "```\n",
        "# Train method hides internal details\n",
        "pipeline.train(X, y)\n",
        "```\n",
        "\n",
        "Now the internal structure can evolve without breaking outer code.\n",
        "\n",
        "---\n",
        "\n",
        "### Code Explanation (Bullets)\n",
        "\n",
        "* `pipeline.train(X, y)` wraps the logic and exposes only what’s needed.\n",
        "\n",
        "* Consumers don’t need to know about trainers, models, or optimizers.\n",
        "\n",
        "* If internals change (e.g., optimizer is replaced), outer code stays intact.\n",
        "\n",
        "---\n",
        "\n",
        "### Why It’s So Important\n",
        "* Low coupling: Changes are isolated to components.\n",
        "\n",
        "* Better abstraction: Users interact at a high level.\n",
        "\n",
        "* Testability: Easier to mock and unit test.\n",
        "\n",
        "* Flexibility: Swap internal components without widespread impact.\n",
        "\n",
        "---\n",
        "\n",
        "### Applications\n",
        "* MLOps tooling\n",
        "\n",
        "* Modular ML workflows\n",
        "\n",
        "* Model deployment APIs\n",
        "\n",
        "* Version-controlled experiment runners\n",
        "\n",
        "---\n",
        "\n",
        "### Conclusion\n",
        "The Law of Demeter teaches us to write ML code that’s easier to maintain, evolve, and collaborate on. Your pipeline shouldn’t have to “know a guy who knows a guy.” Adopt these patterns early, and your ML projects will scale with confidence. Thanks for reading my article, let me know if you have any suggestions or similar implementations via the comment section. Until then, see you next time. Happy coding!\n",
        "\n",
        "---\n",
        "\n",
        "### Before you go\n",
        "* Be sure to Like and Connect Me\n",
        "* Follow Me : [Medium](https://medium.com/@tanunprabhu95) | [GitHub](https://github.com/Tanu-N-Prabhu) | [LinkedIn](https://ca.linkedin.com/in/tanu-nanda-prabhu-a15a091b5) | [Python Hub](https://github.com/Tanu-N-Prabhu/Python)\n",
        "* [Check out my latest articles on Programming](https://medium.com/@tanunprabhu95)\n",
        "* Check out my [GitHub](https://github.com/Tanu-N-Prabhu) for code and [Medium](https://medium.com/@tanunprabhu95) for deep dives!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bmNjQsBcxqgV"
      }
    }
  ]
}